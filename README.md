# Back-propagating reward signals in model-based Reinforcement Learning.

## Abstract
This research project aims to enhance sample efficiency and stability in model-based reinforcement learning. The core idea of this method is to back-propagate actual reward signals from the environment instead of relying on a reward function approximation. Accordingly, updating value function in the vicinity of reward signals and back-propagating the values reversed in time mitigates the problem of reward function inaccuracy and reward scarcity. 
